\documentclass[a4paper]{article}

%\VignetteIndexEntry{PhyloSim}
%\VignettePackage{phylosim}
%\VignetteDepends{R.oo}

% Packages
\usepackage{times}

% Definitions
\newcommand{\psim}{{\tt PhyloSim}}
\newcommand{\slan}{{\tt S}}
\newcommand{\rlan}{{\tt R}}
\newcommand{\lattice}{{\tt lattice}}
\newcommand{\code}[1]{{\tt #1}}
\setlength{\parindent}{0in}
\setlength{\parskip}{.1in}
\usepackage{fullpage}
\usepackage{hyperref}

% setup hyperref
\hypersetup{
	colorlinks=true,
	linkcolor=blue
}

\title{The \psim\ package}
\author{Botond Sipos and Tim Massingham}

\usepackage{Sweave}
\begin{document}

\maketitle

\tableofcontents

\section{Getting help}
\begin{itemize}

\item{\psim\ is extensively documented, the documentation of the \psim\ class is probably a good entry point for beginners.}
\item{Serious users might consider to read all class documentations providing more focused examples.}
\item{Additional examples can be found at \href{http://github.com/sbotond/phylosim/tree/master/examples/}{http://github.com/sbotond/phylosim/tree/master/examples/}.}
\item{The \code{ll()} method list the methods and virtual field implemented in the immediate class of an object which is useful as "proto-documentation".}

\end{itemize}

\section{Advanced examples}

\subsection{Simulating "domains" and heterogeneous evolution}

The following code illustrates how to set up a more complicated simulation of amino acid sequences involving "domains" and heterogeneous evolution.

First, load the package:
<<echo=FALSE,results=hide>>=
options(width=90)
@
<<echo=TRUE>>=
library(phylosim)
@

Use the \code{ll()} method to list the methods and virtual fields implemented in the \code{Sequence} class:
<<echo=TRUE>>=
ll(Sequence())
@

Enable the "fast \& careless mode":
<<echo=TRUE>>=
PSIM_FAST <- TRUE
@
Construct substitution process objects:
<<echo=TRUE>>=
wag <- WAG()
jtt <- JTT()
lg <- LG()
pam <- PAM()
@
Get an object summary for \code{wag}:
<<echo=TRUE>>=
summary(wag)
@
Get a bubble plot of \code{wag}:
<<echo=TRUE,fig=TRUE>>=
plot(wag, scale = 0.8)
@

Construct a continuous deletor process:
<<echo=TRUE>>=
cont.del <- ContinuousDeletor(rate = 0.5, max.length = 10, 
    dist = expression(rnorm(1, mean = 5, sd = 3)))
@
Construct the template sequence for the \code{cont.ins.lg} insertion process:
<<echo=TRUE>>=
templ.seq.wag <- AminoAcidSequence(length = 10)
@

Clone the template sequence for the \code{cont.ins.wag} process:
<<echo=TRUE>>=
templ.seq.lg <- clone(templ.seq.wag)
@

Construct continuous insertor process object \code{cont.ins.wag}:
<<echo=TRUE>>=
cont.ins.wag <- ContinuousInsertor(rate = 0.5, max.length = 10, 
    dist = expression(rnorm(1, mean = 5, sd = 3)))
@

Construct continuous insertor process object \code{cont.ins.lg}:
<<echo=TRUE>>=
cont.ins.lg <- ContinuousInsertor(rate = 0.5, max.length = 10, 
    dist = expression(rnorm(1, mean = 5, sd = 3)))
@

Setting up the template sequences for the insertion processes:
<<echo=TRUE>>=
templ.seq.wag$processes <- list(list(wag, cont.ins.wag, cont.del))
templ.seq.lg$processes <- list(list(lg, cont.ins.lg, cont.del))
@

Now the \code{cont.ins.lg} process samples the states from the equilibrium distribution of the \code{LG} model and \code{cont.ins.wag} samples the states from the \code{WAG} model.

Disabling write protection for the insertion processes:
<<echo=TRUE>>=
cont.ins.wag$writeProtected <- FALSE
cont.ins.lg$writeProtected <- FALSE
@

Setting the template sequence for the insertion processes:
<<echo=TRUE>>=
cont.ins.wag$templateSeq <- templ.seq.wag
cont.ins.lg$templateSeq <- templ.seq.lg
@

Setting up the insert hook for the insertion processes: 
<<echo=TRUE>>=
cont.ins.wag$insertHook <- function(seq, target.seq, event.pos, 
    insert.pos) {
    plusInvGamma(seq, process = wag, pinv = 0.4, shape = 0.6)
    return(seq)
}
cont.ins.lg$insertHook <- function(seq, target.seq, event.pos, 
    insert.pos) {
    plusInvGamma(seq, process = lg, pinv = 0.4, shape = 0.6)
    return(seq)
}
@
Insert hook functions are called just before inserting the sequence generated by the insertion process.
This function allows to perform arbitrary modifications on the inserted sequence object. In this case the
insert hook functions will sample the site-process specific rate multipliers of the substitution processes from an invariants plus discrete gamma model.

Now the processes are in place, so it is time to set up the root sequence.

<<echo=TRUE>>=
seq <- AminoAcidSequence(length = 60)
@

Now we will create a pattern of processes:

<<echo=TRUE>>=
process.pattern <- c(rep(list(list(wag, cont.del, cont.ins.wag)), 
    times = 20), rep(list(list(jtt)), times = 20), rep(list(list(lg, 
    cont.del, cont.ins.lg)), times = 20))
@

The "left linker", "core" and "right linker" regions evolve by different sets of processes. The core region has no indel processes attached, so its length will remain constant.

Apply the process pattern to the root sequence:
<<echo=TRUE>>=
seq$processes <- process.pattern
@

Set up site specific rates by iterating over sites and sampling rates from 
a substitution process specific distribution:
<<echo=TRUE>>=
for (i in 1:seq$length) {
    if (isAttached(seq$sites[[i]], jtt)) {
        while ((site.rate <- rnorm(1, mean = 0.001, sd = 0.01)) < 
            0) {
        }
        setRateMultipliers(seq, jtt, site.rate, index = i)
    }
    else if (isAttached(seq$sites[[i]], wag)) {
        plusInvGamma(seq, process = wag, pinv = 0.4, shape = 0.6, 
            index = i)
    }
    else if (isAttached(seq$sites[[i]], lg)) {
        plusInvGamma(seq, process = lg, pinv = 0.4, shape = 0.6, 
            index = i)
    }
}
@

Sample the states of the root sequence from the attached substitution processes:
<<echo=TRUE>>=
sampleStates(seq)
print(seq)
@

Plot the total rates of the sites:
<<echo=TRUE,fig=TRUE>>=
plot(seq)
@

Read in a tree using the \code{ape} package:
<<echo=FALSE,results=hide>>=
cat("(((t2:0.1231297638,t4:0.1231297638):0.2131353685,(t3:0.02843331083,t5:0.02843331083):0.3078318214):0.1698207644,t1:0.5060858966);",file="smalldemotree.nwk")
@
<<echo=TRUE>>=
tree <- read.tree(file = "smalldemotree.nwk")
@
<<echo=FALSE,results=hide>>=
file.remove("smalldemotree.nwk");
@

Construct the simulation object and get an object summary:
<<echo=TRUE>>=
sim <- PhyloSim(phylo = tree, root.seq = seq)
summary(sim)
@

Plot the simulation object:
<<echo=TRUE,fig=TRUE>>=
plot(sim)
@

Create a node hook function:
<<echo=TRUE>>=
node.hook <- function(seq) {
    for (site in seq$sites) {
        if (isAttached(site, jtt)) {
            attachProcess(site, pam)
        }
    }
    return(seq)
}
@

A "node hook" is a function which accepts a Sequence object
through the named argument "seq" and returns a Sequence object.
After simulating the branch leading to the node, the resulting
\code{Sequence} object is passed to the node hook and the returned object
is used to simulate the downstream branches.

Attach the hook to node 8:
<<echo=TRUE>>=
attachHookToNode(sim, node = 8, fun = node.hook)
@

The \code{node.hook} function will attach the \code{pam} substitution process to all
sites which have the \code{jtt} process attached (the "core" region). The affected sites 
will evolve with a doubled rate by a mixture of substitution processes in the clade defined by the node - \code{(t4, t2)}.

Run the simulation:
<<echo=TRUE>>=
Simulate(sim)
@

Plot the resulting alignment alongside the tree:
<<echo=TRUE,fig=TRUE>>=
plot(sim)
@

Save the resulting alignment, omit the internal nodes:
<<echo=TRUE>>=
saveAlignment(sim, file = "example_V1_aln.fas", skip.internal = TRUE)
@
<<echo=FALSE,results=hide>>=
file.remove("example_V1_aln.fas")
@

Disable fast mode:
<<echo=TRUE>>=
rm(PSIM_FAST)
@


\subsection{Evolving codon sequences}

Enable "fast \& careless" mode:
<<echo=TRUE>>=
PSIM_FAST <- TRUE
@
Construct a GY94 codon substitution model:
<<echo=TRUE>>=
p <- GY94()
@
Set the transition/transversion rate ratio:
<<echo=TRUE>>=
p$kappa = 2
@
Sample codon frequencies from a normal distribution:
<<echo=TRUE>>=
codon.freqs <- abs(rnorm(61, mean = 10, sd = 3))
codon.freqs <- codon.freqs/sum(codon.freqs)
p$equDist <- codon.freqs
@
Get object summary for p:
<<echo=TRUE>>=
summary(p)
@

Get a bubble plot of \code{p}:
<<echo=TRUE,fig=TRUE>>=
plot(p,scale=0.5)
@

Construct a discrete deletor process:
<<echo=TRUE>>=
d<-DiscreteDeletor(
        rate=1,
        sizes=1:4,
        probs=c(4,3,2,1)/10
);
@

Construct a discrete insertor process inserting neutrally evolving sites:
<<echo=TRUE>>=
i<-DiscreteInsertor(
        rate=1.5,
        sizes=1:4,
        probs=c(4,3,2,1)/10,
        template.seq=CodonSequence(length=4,processes=list(list(p)))
);
@

Construct root sequence and attach process \code{p}:
<<echo=TRUE>>=
s<-CodonSequence(length=30,processes=list(list(p)))
@

Sample omegas from a discrete model:
<<echo=TRUE>>=
omegaVarM3(s,p,omegas=c(0,1,2),probs=c(2/4,1/4,1/4))
@

Plot the omega values across sites:
<<echo=TRUE,fig=TRUE>>=
plotParametersAtSites(s,p,"omega");
@

Sample states:
<<echo=TRUE>>=
sampleStates(s)
@
Construct the simulation object:
<<echo=FALSE,results=hide>>=
cat("(((t2:0.1231297638,t4:0.1231297638):0.2131353685,(t3:0.02843331083,t5:0.02843331083):0.3078318214):0.1698207644,t1:0.5060858966);",file="smalldemotree.nwk")
@
<<echo=TRUE>>=
sim <- PhyloSim(root.seq = s, phylo = read.tree("smalldemotree.nwk"))
@
<<echo=FALSE,results=hide>>=
file.remove("smalldemotree.nwk");
@
Create a node hook function and attach to node 8:
<<echo=TRUE>>=
node.hook <- function(seq) {
	setOmegas(seq, p, 1)
	attachProcess(seq, d)
	attachProcess(seq, i)
	return(seq)
}
attachHookToNode(sim, node = 8, fun = node.hook)
@

The \code{node.hook} function will set all omegas to 1 and attach the insertion process \code{i} and deletion process \code{d}. Hence, the sequences will evolve neutrally and with indels in the clade defined by node 8 - \code{(t4, t2)}.

Disable fast mode just before simulation in order to preserve branch statistics:
<<echo=TRUE>>=
rm(PSIM_FAST)
@

Run the simulation:
<<echo=TRUE>>=
Simulate(sim)
@

Plot the resulting alignment alongside the tree:
<<echo=TRUE,fig=TRUE>>=
plot(sim)
@

Export the nonsynonymous substitution counts as a phylo object:
<<echo=TRUE>>=
nsyn.subst<-exportStatTree(sim,"nr.nsyn.subst")
@

Plot the exported phylo object:
<<echo=TRUE,fig=TRUE>>=
plot(nsyn.subst)
nodelabels()
@

Save the resulting alignment:
<<echo=TRUE>>=
saveAlignment(sim, file = "example_V2_aln.fas", )
@
<<echo=FALSE,results=hide>>=
file.remove("example_V2_aln.fas")
@

\subsection{Implementing a new process}

The following code demonstrates how to implement a process which performs inverted duplications. In this example
we simply replace the function object stored in the \code{generateBy} virtual field of and \code{GeneralInsertor}
object. We could have defined a new class and set the insert generating function in the constructor method.

Enable fast \& careless mode:
<<echo=TRUE>>=
PSIM_FAST<-TRUE;
@

Construct a DiscreteInsertor process:
<<echo=TRUE>>=
ivd<-DiscreteInsertor(rate=0.04,sizes=c(4,6),probs=c(2/3,1/3));
@

Set template sequence just to make the process object happy:
<<echo=TRUE>>=
ivd$templateSeq<-NucleotideSequence(length=1);
@

Replace the function object stored in the 
\code{generateBy} virtual field. See the documentation of the 
\code{GeneralInsertor} class:
<<echo=TRUE>>=
ivd$generateBy<-function(process=NA,length=NA,target.seq=NA,event.pos=NA,insert.pos=NA){
	# get the target sequence length
	target.length<-target.seq$length;
	# construct a vector with the positions to copy:
	positions<-(insert.pos+1):(insert.pos + length)
	# discard illegal positions:
	positions<-positions[ positions > 0 & positions <= target.length];
	# copy subsequence
	insert<-copySubSequence(target.seq,positions,process);
	# reverse complement sequence,
	# take care, the class of this objects is "Sequence":
	revComp.NucleotideSequence(insert);
	# do not allow nested insertions:
	setRateMultipliers(insert,ivd,0);
	# return insert	
	return(insert);
}
@
Now we have a process which perfroms inverted duplications.

Construct a JC69 process object:
<<echo=TRUE>>=
p<-JC69();
@

Construct root sequence object:
<<echo=TRUE>>=
s<-NucleotideSequence(length=50)
@
Attach processes via virtual field:
<<echo=TRUE>>=
s$processes<-list(list(p,ivd))
@

Sample states from the equilibrium
distribution of the attached processes:
<<echo=TRUE>>=
sampleStates(s)
@
Detach the substitution process:
<<echo=TRUE>>=
detachProcess(s,p)
@
Create among-sites rate variation for the inverted duplication
process by sampling rate multipliers from an I+G model:
<<echo=TRUE>>=
plusGamma(s,ivd,pinv=0.5,shape=0.5)
@
Construct simulation object:
<<echo=FALSE,results=hide>>=
cat("(((t2:0.1231297638,t4:0.1231297638):0.2131353685,(t3:0.02843331083,t5:0.02843331083):0.3078318214):0.1698207644,t1:0.5060858966);",file="smalldemotree.nwk")
@
<<echo=TRUE>>=
sim<-PhyloSim(root.seq=s, phylo=read.tree("smalldemotree.nwk"));
@
<<echo=FALSE,results=hide>>=
file.remove("smalldemotree.nwk");
@
Run simulation:
<<echo=TRUE>>=
Simulate(sim)
@
Plot tree and alignment:
<<echo=TRUE>>=
plot(sim)
@

Save alingment:
<<echo=TRUE>>=
saveAlignment(sim,file="example_V3.fas");
@
<<echo=FALSE,results=hide>>=
file.remove("example_V3.fas");
@
Disable fast \& careless mode:
<<echo=TRUE>>=
rm(PSIM_FAST);
@


\section{The details of the field deletion model}

A natural way to incorporate deletions into the Gillespie framework is to assign an individual rate to every possible deletion event. Modelling in this manner is extremely general but requires a lot of specification: not only individual sites' tolerance to deletion but also of how they interact with neighbouring sites. Instead we propose a more restricted ``field model'' of deletion that generalises previous work to allow rate deletions occur to vary across the sequence but only requires one parameter per site -- its deletion tolerance -- to be specified. Under this model, deletions are proposed in same manner as other models, specifying a rate of occurrence and a distribution of lengths and then assuming that the location and orientation of the deletion is chosen uniformly, but proposed deletions may then be rejected based on sites they propose to remove.
 
Firstly consider only single-site deletions and let each site, $i$, in the sequence have an associated deletion tolerance parameter, $d_i \in [0,1]$, representing the probability that it is actually deleted given a deletion is proposed. A proposal / acceptance step is equivalent to just proposing at a slower rate, so this is just a special case of the most general model but one that can be implemented efficiently as a single Gillespie event (a deletion occurred somewhere) rather than a large number of slower events (treating every possible deletion separately). Sites where $d_i=1$ are deleted at the background rate, sites with $d_i < 1$ are deleted more slowly, and sites with $d_i=0$ are never deleted. For proposed deletions that span multiple sites, ${\cal I}$, each site is considered independently and the proposed deletion is accepted if and only if every site accepts it: the total probability of acceptance is therefore $\prod_{i\in {\cal I}} d_i$. 

It is natural to think of the background rate of deletion as a neutral rate but this is not necessary and can lead to the Gillespie algorithm becoming inefficient, for example: an extremely deletion intolerant sequence will reject almost all deletions proposed and so waste many steps. Instead we can rescale the process so that deletions are proposed at a rate equal to what would occur if the entire sequence had a deletion tolerance equal to its most tolerant site (deletion tolerance $d$) and then accept a deletion spanning sites ${\cal I}$ with probability $d_i / d$. Table~\ref{distributions} gives the rate scaling factor and distribution of deletion lengths after scaling for a variety of distributions that could be used to model deletion length. In most cases, the rescaled distribution of deletion lengths is a member of the same family as the ``neutral'' process.

\begin{table}[h]
\begin{tabular}{llll} 
Distribution & Density & Scale factor & Rescaled distribution \\ \hline
Geometric, ${\rm Geom}(\lambda)$
	& $\lambda^{k-1}(1-\lambda)$ 
	& $\smash{ d \frac{1-\lambda}{1 - d\lambda}}$ 
	& ${\rm Geom}(d\lambda)$ \\
Poisson + 1, ${\rm Po_{+1}}(\lambda)$	
	& $\smash{ \frac{e^{-\lambda}\lambda^{k-1}}{\Gamma(k)}  }$ 
	& $d \smash{ e^{-\lambda (1-d)} }$ 
	& ${\rm Po_{+1}}(d\lambda)$ \\
Conway-Maxwell Poisson + 1, ${\rm CMP_{+1}}(\lambda,\nu)$ 
	& $\smash{ \frac{\lambda^{k-1}}{\Gamma(k)^\nu {\cal Z}(\lambda,\nu)} }$ 
	& $\smash{d \frac{ {\cal Z}(\lambda,\nu)}{ {\cal Z}(d\lambda,\nu)}}$ 
	&  ${\rm CMP_{+1}}(d\lambda,\nu)$ \\
Negative Binomial + 1, ${\rm NB_{+1}}(\lambda,r)$ 
	& $\smash{  \frac{\Gamma(r+k-1)}{\Gamma(k)\Gamma(r)} (1-\lambda)^r \lambda^{k-1} } $
	& $\smash{ d\frac{(1-\lambda)^r}{(1-d\lambda)^r} }$ 
	& ${\rm NB_{+1}}(d\lambda,r)$ \\\hline
\end{tabular}
\caption{The rate scaling factor and distribution of deletion lengths after scaling for a variety of distributions that could be used to model deletion length.}
\label{distributions}
\end{table}

\end{document}




